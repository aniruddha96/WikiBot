{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "669de393",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import re\n",
    "from psaw import PushshiftAPI\n",
    "api = PushshiftAPI()\n",
    "from datetime import datetime\n",
    "import json\n",
    "import pysolr\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "94f52b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "subreddits = ['science','worldnews','news','food','askscience','space','mildlyinteresting','history','UpliftingNews'\n",
    "             'philosophy','technology','politics']\n",
    "def getSubmissionsBySubReddit(subreddit,limit):\n",
    "    gen = api.search_submissions(subreddit=[subreddit], \n",
    "                             filter=['id','url','author', 'title', 'score',\n",
    "                                       'subreddit','selftext','num_comments'], \n",
    "                             limit = limit, \n",
    "                             num_comments=\">10\")\n",
    "    submission_list = list(gen)\n",
    "    submission_list = [item.d_ for item in submission_list]\n",
    "    submission_df = pd.DataFrame.from_dict(submission_list)\n",
    "    submission_df = submission_df.fillna(\"\")\n",
    "    return convertSubmissionsTofinalSchema(submission_df,topic=None)\n",
    "\n",
    "def getSubmissionsBySubRedditsAndTopic(subreddits,topic,limit,keyword):\n",
    "    gen = api.search_submissions(subreddit=subreddits,\n",
    "                             filter=['id','url','author', 'title', 'score',\n",
    "                                       'subreddit','selftext','num_comments'], \n",
    "                             limit = limit, \n",
    "                             num_comments=\">10\", q=keyword) \n",
    "\n",
    "    submission_list = list(gen)\n",
    "    submission_list = [item.d_ for item in submission_list]\n",
    "    submission_df = pd.DataFrame.from_dict(submission_list)\n",
    "    submission_df = submission_df.fillna(\"\")\n",
    "    return convertSubmissionsTofinalSchema(submission_df,topic=topic)\n",
    "\n",
    "def convertSubmissionsTofinalSchema(submission_df,topic):\n",
    "    submission_df = submission_df[submission_df.selftext!='[removed]']    \n",
    "    submission_df = submission_df[submission_df.selftext!='[deleted]']\n",
    "    submission_df = submission_df[submission_df.selftext!='']\n",
    "    submission_df['is_submission'] = True\n",
    "    submission_df['body'] = submission_df['selftext']\n",
    "    submission_df['parent_id'] = None\n",
    "    submission_df['parent_body'] = None\n",
    "    submission_df['topic'] = topic\n",
    "    submission_df=submission_df.rename({'url':'full_link'},axis=1)\n",
    "    submission_df=submission_df.rename({'score':'upvotes'},axis=1)\n",
    "    res= submission_df[['id','subreddit','full_link','title','body','selftext','author','is_submission','parent_id'\n",
    "                          ,'parent_body','topic','created_utc','upvotes']]\n",
    "    return res\n",
    "\n",
    "def convertCommentsToFinalSchema(comments_df,topic=None):\n",
    "    comments_df = comments_df[comments_df.body!='[removed]']    \n",
    "    comments_df = comments_df[comments_df.body!='[deleted]']\n",
    "    comments_df = comments_df[comments_df.body!='']\n",
    "    comments_df['is_submission'] = False\n",
    "    comments_df['topic'] = topic\n",
    "    comments_df['parent_body'] = None\n",
    "    comments_df['selftext'] = None\n",
    "    comments_df['title'] = None\n",
    "    comments_df['parent_id'] = comments_df['parent_id'].apply(lambda x:x.split('_')[1] )\n",
    "    comments_df=comments_df.rename({'permalink':'full_link'},axis=1)\n",
    "    res= comments_df[['id','subreddit','full_link','title','body','selftext','author','is_submission','parent_id'\n",
    "                          ,'parent_body','topic','created_utc','score']]\n",
    "    return res\n",
    "\n",
    "def fetchCommentsForSubmission(submission):\n",
    "    comments_lst = list(api.search_comments(link_id=submission[\"id\"].iloc[0], subreddit=[submission[\"subreddit\"].iloc[0]],\n",
    "                                        filter=['id','parent_id','permalink','author', 'title', \n",
    "                                                'subreddit','body','num_comments','score']))\n",
    "    \n",
    "    comments_lst = [item.d_ for item in comments_lst]\n",
    "    comments_df = pd.DataFrame.from_dict(comments_lst)\n",
    "    comments_df = comments_df.fillna(\"\")\n",
    "    \n",
    "    if len(comments_lst) == 0:\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    if 'permalink' not in comments_df.columns:\n",
    "        print('no permalink')\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    return convertCommentsToFinalSchema(comments_df,topic=submission[\"topic\"].iloc[0])\n",
    "\n",
    "def populateComments(submission):\n",
    "    comments = fetchCommentsForSubmission(submission)\n",
    "    if comments.size == 0:\n",
    "        return pd.concat([submission])\n",
    "    res = pd.concat([submission,comments])\n",
    "    merged = pd.merge(res,res,left_on='parent_id',right_on='id',how='left')\n",
    "    merged = merged.rename({'id_x':'id','subreddit_x':'subreddit','full_link_x':'full_link',\n",
    "                        'title_x':'title','body_x':'body','selftext_x':'selftext','author_x':'author',\n",
    "                        'is_submission_x':'is_submission','parent_id_x':'parent_id',\n",
    "                        'topic_x':'topic','body_y':'parent_body','created_utc_x':'created_utc','score_x':'upvotes'},axis=1)\n",
    "    final= merged[['id','subreddit','full_link','title','body','selftext','author','is_submission','parent_id'\n",
    "                          ,'parent_body','topic','created_utc','upvotes']]\n",
    "    # final = final.set_index('id')\n",
    "    \n",
    "    return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e3c06125",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df = pd.concat([ \n",
    "getSubmissionsBySubRedditsAndTopic(subreddits,topic='Politics',limit=120,keyword='Democrats'),\n",
    "getSubmissionsBySubRedditsAndTopic(subreddits,topic='Politics',limit=120,keyword='Republican'),\n",
    "getSubmissionsBySubRedditsAndTopic(subreddits,topic='Environment',limit=120,keyword='Environment'),\n",
    "getSubmissionsBySubRedditsAndTopic(subreddits,topic='Environment',limit=120,keyword='Climate change'),\n",
    "getSubmissionsBySubRedditsAndTopic(subreddits,topic='Environment',limit=120,keyword='Solar energy'),\n",
    "getSubmissionsBySubRedditsAndTopic(subreddits,topic='Technology',limit=120,keyword='Programming'),\n",
    "getSubmissionsBySubRedditsAndTopic(subreddits,topic='Technology',limit=120,keyword='Computer'),\n",
    "getSubmissionsBySubRedditsAndTopic(subreddits,topic='Technology',limit=120,keyword='Blockchain'),\n",
    "getSubmissionsBySubRedditsAndTopic(subreddits,topic='Healthcare',limit=120,keyword='Healthcare'),\n",
    "getSubmissionsBySubRedditsAndTopic(subreddits,topic='Healthcare',limit=120,keyword='Covid'),\n",
    "getSubmissionsBySubRedditsAndTopic(subreddits,topic='Education',limit=120,keyword='Education'),\n",
    "getSubmissionsBySubRedditsAndTopic(subreddits,topic='Education',limit=120,keyword='Learning'),\n",
    "getSubmissionsBySubRedditsAndTopic(subreddits,topic='Education',limit=120,keyword='School'),\n",
    "getSubmissionsBySubReddit('ExplainLikeImFive',150),\n",
    "getSubmissionsBySubReddit('FoodForThought',150),\n",
    "getSubmissionsBySubReddit('ChangeMyView',150),\n",
    "getSubmissionsBySubReddit('TodayILearned',150)\n",
    "])\n",
    "print(submission_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1ff63e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "submissionAndComment = pd.DataFrame()\n",
    "for i in tqdm(range(0,submission_df.shape[0])):\n",
    "    submission = submission_df.iloc[[i]]\n",
    "    final = populateComments(submission)\n",
    "    submissionAndComment = pd.concat([submissionAndComment,final])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "779a6127",
   "metadata": {},
   "outputs": [],
   "source": [
    "submissionAndComment['upvotes'] = submissionAndComment['upvotes'].fillna(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d9c3ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "submissionAndComment.to_csv('D:\\\\scrape2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6deaa49",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(submissionAndComment.topic.unique())\n",
    "print(submissionAndComment.upvotes.dtype)\n",
    "print(submissionAndComment.upvotes.isna().unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99e4c095",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "26de051ba29f2982a8de78e945f0abaf191376122a1563185a90213a26c5da77"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
